# üß™ Complete Local Testing Guide with Expected Results

**Goal:** Test models locally after hyperparameter tuning, measure salience scores, gain confidence BEFORE mainnet deployment

**Duration:** 2-4 hours  
**Risk:** Zero (all local testing)  
**Outcome:** Know your expected performance and readiness level

---

## üìç Current Status

```
‚úÖ Phase 1: Training/Tuning Complete (or in progress)
‚è≥ Phase 1.5: LOCAL TESTING ‚Üê YOU ARE HERE
‚è∏Ô∏è Phase 2: Mainnet Deployment (after confidence)
```

---

# STAGE 1: Verify Training Completion

## Goal
Confirm all 11 challenge models were trained successfully and saved correctly.

## Steps

### Step 1.1: Check Training Logs

```bash
cd /home/ocean/Nereus/SN123

# Check if training completed
tail -50 logs/training/training_current.log | grep -i "summary\|complete\|error"
```

**Expected Output (Success):**
```
‚úÖ Training Summary for ETH-LBFGS
‚úÖ Model saved to models/tuned/ETH-LBFGS
‚úÖ Training Summary for BTC-LBFGS-6H
‚úÖ Model saved to models/tuned/BTC-LBFGS-6H
...
‚úÖ All 11 challenges trained successfully
```

**If You See Errors:**
```
‚ùå ERROR: Out of memory
‚ùå ERROR: Model training failed for CHALLENGE_NAME
```
‚Üí Action: Fix errors before proceeding (see TRAINING_TROUBLESHOOTING_GUIDE.md)

---

### Step 1.2: Verify Model Files Exist

```bash
cd /home/ocean/Nereus/SN123

# List all tuned models
ls -la models/tuned/
```

**Expected Output:**
```
drwxr-xr-x  ETH-LBFGS/
drwxr-xr-x  BTC-LBFGS-6H/
drwxr-xr-x  ETH-HITFIRST-100M/
drwxr-xr-x  ETH-1H-BINARY/
drwxr-xr-x  EURUSD-1H-BINARY/
drwxr-xr-x  GBPUSD-1H-BINARY/
drwxr-xr-x  CADUSD-1H-BINARY/
drwxr-xr-x  NZDUSD-1H-BINARY/
drwxr-xr-x  CHFUSD-1H-BINARY/
drwxr-xr-x  XAUUSD-1H-BINARY/
drwxr-xr-x  XAGUSD-1H-BINARY/

Total: 11 directories ‚úÖ
```

**Check Each Model Has Required Files:**
```bash
# Check one model in detail
ls -la models/tuned/ETH-LBFGS/
```

**Expected Output:**
```
-rw-r--r-- config.json          # Model configuration
-rw-r--r-- feature_indices.pkl  # Feature selection
-rw-r--r-- lstm_model.h5        # LSTM weights
-rw-r--r-- scaler.pkl            # Data scaler
-rw-r--r-- xgb_model.json        # XGBoost model
```

**Result:** 
- ‚úÖ **PASS:** All 11 models exist with complete files ‚Üí Proceed to Stage 2
- ‚ùå **FAIL:** Missing models or files ‚Üí Retrain missing challenges

---

# STAGE 2: Model Loading Test

## Goal
Verify all 11 models load into memory without errors.

## Step 2.1: Test Loading All Models

```bash
cd /home/ocean/Nereus/SN123
source venv/bin/activate

python << 'EOF'
from scripts.training.model_architecture import VMDTMFGLSTMXGBoost
import os

challenges = [
    'ETH-LBFGS', 'BTC-LBFGS-6H', 'ETH-HITFIRST-100M',
    'ETH-1H-BINARY', 'EURUSD-1H-BINARY', 'GBPUSD-1H-BINARY',
    'CADUSD-1H-BINARY', 'NZDUSD-1H-BINARY', 'CHFUSD-1H-BINARY',
    'XAUUSD-1H-BINARY', 'XAGUSD-1H-BINARY'
]

print("="*80)
print("STAGE 2: Model Loading Test")
print("="*80)
print()

passed = 0
failed = 0

for challenge in challenges:
    model_path = f'models/tuned/{challenge}'
    try:
        model = VMDTMFGLSTMXGBoost.load(model_path)
        print(f"‚úì {challenge}: Loaded successfully")
        passed += 1
    except Exception as e:
        print(f"‚úó {challenge}: FAILED - {str(e)[:60]}")
        failed += 1

print()
print(f"Results: {passed} passed, {failed} failed")
if failed == 0:
    print("‚úÖ ALL MODELS LOADED SUCCESSFULLY - Ready for Stage 3")
else:
    print(f"‚ùå {failed} models failed to load - Fix before proceeding")
EOF
```

**Expected Output (Success):**
```
================================================================================
STAGE 2: Model Loading Test
================================================================================

‚úì ETH-LBFGS: Loaded successfully
‚úì BTC-LBFGS-6H: Loaded successfully
‚úì ETH-HITFIRST-100M: Loaded successfully
‚úì ETH-1H-BINARY: Loaded successfully
‚úì EURUSD-1H-BINARY: Loaded successfully
‚úì GBPUSD-1H-BINARY: Loaded successfully
‚úì CADUSD-1H-BINARY: Loaded successfully
‚úì NZDUSD-1H-BINARY: Loaded successfully
‚úì CHFUSD-1H-BINARY: Loaded successfully
‚úì XAUUSD-1H-BINARY: Loaded successfully
‚úì XAGUSD-1H-BINARY: Loaded successfully

Results: 11 passed, 0 failed
‚úÖ ALL MODELS LOADED SUCCESSFULLY - Ready for Stage 3
```

**Time:** ~30 seconds

**Result:**
- ‚úÖ **PASS:** All 11 models load ‚Üí Proceed to Stage 3
- ‚ùå **FAIL:** Any model fails to load ‚Üí Check error, retrain that model

---

# STAGE 3: Backtest Performance

## Goal
Test models on recent historical data (last 30 days) to estimate accuracy and salience scores.

## Step 3.1: Run Complete Backtest

```bash
cd /home/ocean/Nereus/SN123
source venv/bin/activate

# Run comprehensive backtest
python scripts/testing/backtest_models.py | tee backtest_results_$(date +%Y%m%d).txt
```

**Time:** 5-10 minutes (processes ~30 days of data for 11 challenges)

**Expected Output - Per Challenge:**

### Binary Challenge Example (ETH-1H-BINARY):
```
============================================================
Backtesting: ETH-1H-BINARY
============================================================
‚úì Model loaded
Test period: 2024-11-12 to 2024-12-12
Test samples: 720
Test sequences: 700
Features: 87

üìä Results:
  Accuracy: 0.6714 (67.14%)
  AUC: 0.7023
  Predictions: Class 0: 312, Class 1: 388
  Estimated Salience: 0.6856

‚úÖ Good performance - predicting both classes
```

### LBFGS Challenge Example (ETH-LBFGS):
```
============================================================
Backtesting: ETH-LBFGS
============================================================
‚úì Model loaded
Test period: 2024-11-12 to 2024-12-12
Test samples: 720
Test sequences: 700
Features: 87

üìä Embedding Statistics:
  Shape: (700, 17)
  Mean (first 5): [0.0234, -0.0156, 0.0421, -0.0087, 0.0198]
  Std (first 5): [0.2341, 0.1987, 0.2654, 0.1876, 0.2123]
  Min (first 5): [-0.8745, -0.7234, -0.8912, -0.6543, -0.7654]
  Max (first 5): [0.9123, 0.8234, 0.9456, 0.7890, 0.8567]
  Valid embeddings: ‚úì
  Estimated Salience: 2.1234

‚úÖ Good embedding diversity
```

---

## Step 3.2: Review Summary

**After all challenges complete, you'll see:**

```
================================================================================
üìä BACKTEST SUMMARY
================================================================================

Binary Challenges:
  ETH-1H-BINARY:
    Accuracy: 0.6714 (67.14%)
    AUC: 0.7023
    Est. Salience: 0.6856
    
  EURUSD-1H-BINARY:
    Accuracy: 0.6543 (65.43%)
    AUC: 0.6845
    Est. Salience: 0.6172
    
  GBPUSD-1H-BINARY:
    Accuracy: 0.7012 (70.12%)
    AUC: 0.7234
    Est. Salience: 0.8048
    
  [... other binary challenges ...]

  Average Accuracy: 0.6687 (66.87%)
  Average Est. Salience: 0.6749

LBFGS Challenges:
  ETH-LBFGS:
    Valid: True
    Embedding Std: 1.0617
    Est. Salience: 2.1234
    
  BTC-LBFGS-6H:
    Valid: True
    Embedding Std: 0.9876
    Est. Salience: 1.9752
    
  ETH-HITFIRST-100M:
    Valid: True
    Embedding Std: 0.8234
    Est. Salience: 1.6468

  Average Est. Salience: 1.9151

================================================================================
‚úÖ MAINNET READINESS ASSESSMENT
================================================================================

Models tested: 11/11
Binary Avg Accuracy: 0.6687 (66.87%)
  ‚úì GOOD - Should perform well on mainnet

Overall Est. Salience: 1.4521
  ‚úì GOOD - Should rank well

================================================================================
üìã RECOMMENDATION
================================================================================

‚úÖ READY FOR MAINNET DEPLOYMENT

Next steps:
1. Save these baseline results
2. Follow Phase 2 in COMPLETE_ROADMAP_TO_FIRST_PLACE.md
3. Deploy to mainnet with confidence!
```

---

## Step 3.3: Interpret Results

### Performance Bands

**Binary Challenges (Accuracy):**
```
‚úÖ Excellent: ‚â•70%  ‚Üí Top tier performance, deploy immediately!
‚úì  Good:     65-70% ‚Üí Ready for mainnet
‚ö†Ô∏è  Fair:     60-65% ‚Üí Acceptable, monitor closely
‚ùå Poor:     <60%   ‚Üí Consider retraining
```

**LBFGS Challenges (Estimated Salience):**
```
‚úÖ Excellent: ‚â•2.0  ‚Üí Top tier, competitive for #1
‚úì  Good:     1.5-2.0 ‚Üí Solid performance
‚ö†Ô∏è  Fair:     1.0-1.5 ‚Üí Acceptable
‚ùå Poor:     <1.0   ‚Üí Needs improvement
```

**Overall Estimated Salience:**
```
‚úÖ Excellent: ‚â•2.0  ‚Üí Competitive for top 3
‚úì  Good:     1.5-2.0 ‚Üí Should rank in top 10
‚ö†Ô∏è  Fair:     1.0-1.5 ‚Üí Should rank in top 20
‚ùå Poor:     <1.0   ‚Üí May struggle to rank well
```

---

## Step 3.4: Save Baseline Results

```bash
cd /home/ocean/Nereus/SN123

# Save baseline for comparison
cp backtest_results_*.txt baseline_results.txt

# Create summary
cat > baseline_summary.txt << EOF
================================================================================
BASELINE PERFORMANCE - $(date)
================================================================================

Test Period: Last 30 days
Test Date: $(date +%Y-%m-%d)

Binary Challenges Average: $(grep "Binary Avg Accuracy" backtest_results_*.txt | tail -1)
Overall Salience: $(grep "Overall Est. Salience" backtest_results_*.txt | tail -1)
Readiness: $(grep -A 1 "RECOMMENDATION" backtest_results_*.txt | tail -1)

Use this as reference for mainnet performance comparison.
================================================================================
EOF

cat baseline_summary.txt
```

**Result:** Baseline saved for future comparison

---

# STAGE 4: Prediction Speed Test

## Goal
Ensure models can generate predictions fast enough for real-time mining (<5 seconds per prediction).

## Step 4.1: Test Prediction Latency

```bash
cd /home/ocean/Nereus/SN123
source venv/bin/activate

python << 'EOF'
import time
import pandas as pd
from scripts.training.model_architecture import VMDTMFGLSTMXGBoost
import numpy as np

print("="*80)
print("STAGE 4: Prediction Speed Test")
print("="*80)
print()

# Test most important challenge: ETH-LBFGS
challenge = 'ETH-LBFGS'
print(f"Testing {challenge} (highest weight)...")
print()

times = {}

# Load model
start = time.time()
model = VMDTMFGLSTMXGBoost.load(f'models/tuned/{challenge}')
times['load_model'] = time.time() - start
print(f"‚úì Model loaded: {times['load_model']:.3f}s")

# Load data
start = time.time()
df = pd.read_csv('data/ETH_1h.csv').tail(100)
times['load_data'] = time.time() - start
print(f"‚úì Data loaded: {times['load_data']:.3f}s")

# Prepare features
start = time.time()
X, y, features = model.prepare_data(df)
times['prepare_features'] = time.time() - start
print(f"‚úì Features prepared: {times['prepare_features']:.3f}s")
print(f"  Sequences created: {len(X)}")
print(f"  Features per sequence: {X.shape[2]}")

# Generate prediction (most recent data point)
start = time.time()
pred = model.predict_embeddings(X[-1:])
times['prediction'] = time.time() - start
print(f"‚úì Prediction generated: {times['prediction']:.3f}s")
print(f"  Shape: {pred.shape}")
print(f"  Values (first 5): {pred[0][:5]}")

# Total time
times['total'] = sum(times.values())
print()
print(f"Total time: {times['total']:.3f}s")
print()

# Assessment
if times['total'] < 3.0:
    print("‚úÖ EXCELLENT - Very fast, ready for real-time")
elif times['total'] < 5.0:
    print("‚úì GOOD - Fast enough for mining")
elif times['total'] < 10.0:
    print("‚ö†Ô∏è ACCEPTABLE - Should work but monitor")
else:
    print("‚ùå TOO SLOW - May need optimization")

print()
print("Breakdown:")
print(f"  Model loading: {times['load_model']:.3f}s ({times['load_model']/times['total']*100:.1f}%)")
print(f"  Data loading: {times['load_data']:.3f}s ({times['load_data']/times['total']*100:.1f}%)")
print(f"  Feature prep: {times['prepare_features']:.3f}s ({times['prepare_features']/times['total']*100:.1f}%)")
print(f"  Prediction: {times['prediction']:.3f}s ({times['prediction']/times['total']*100:.1f}%)")
EOF
```

**Expected Output:**
```
================================================================================
STAGE 4: Prediction Speed Test
================================================================================

Testing ETH-LBFGS (highest weight)...

‚úì Model loaded: 0.234s
‚úì Data loaded: 0.089s
‚úì Features prepared: 0.456s
  Sequences created: 80
  Features per sequence: 87
‚úì Prediction generated: 0.123s
  Shape: (1, 17)
  Values (first 5): [0.0234 -0.0156 0.0421 -0.0087 0.0198]

Total time: 0.902s

‚úÖ EXCELLENT - Very fast, ready for real-time

Breakdown:
  Model loading: 0.234s (25.9%)
  Data loading: 0.089s (9.9%)
  Feature prep: 0.456s (50.6%)
  Prediction: 0.123s (13.6%)
```

**Result:**
- ‚úÖ **PASS:** <5 seconds ‚Üí Fast enough for mining
- ‚ö†Ô∏è **SLOW:** 5-10 seconds ‚Üí Acceptable but monitor
- ‚ùå **FAIL:** >10 seconds ‚Üí Needs optimization

---

# STAGE 5: Salience Diversity Test

## Goal
Verify embeddings are diverse (not collapsed) and predictions cover both classes (binary challenges).

## Step 5.1: Test Embedding Diversity

```bash
cd /home/ocean/Nereus/SN123
source venv/bin/activate

python scripts/testing/test_local_salience.py \
    --ticker ETH-1H-BINARY \
    --model-dir models/tuned \
    --data-dir data
```

**Expected Output:**
```
================================================================================
Testing Salience Metrics for ETH-1H-BINARY
================================================================================

‚úì Loading model from models/tuned/ETH-1H-BINARY
‚úì Loading data from data/ETH_1h.csv
‚úì Preparing test data (last 30 days)
  Test sequences: 700

================================================================================
Embedding Diversity Analysis
================================================================================
Embedding shape: (700, 2)
Mean embeddings: [ 0.0234  -0.0156]
Std embeddings: [0.2341  0.1987]
Range embeddings: [1.7869  1.5467]

Diversity Score: 2.1234
  (Higher = more diverse embeddings, better for salience)
Class Separation: 0.3456
  (Higher = better separation between classes)

‚úÖ GOOD - Embeddings are diverse

================================================================================
Prediction Diversity Analysis
================================================================================
Unique predictions: 2 (Class 0, Class 1)
Prediction distribution:
  Class 0: 312 (44.6%)
  Class 1: 388 (55.4%)

‚úÖ EXCELLENT - Model predicts both classes

================================================================================
Estimated Salience Metrics
================================================================================
AUC: 0.7023
Prediction Diversity: 0.9821
Embedding Diversity: 2.1234

Estimated Salience Score: 1.2359

‚úì Should achieve good salience on mainnet
```

**Key Indicators:**
- ‚úÖ **Diversity Score > 1.0:** Good embedding variance
- ‚úÖ **Predicts Both Classes:** Not collapsed to majority class
- ‚úÖ **AUC > 0.55:** Better than random
- ‚úÖ **Est. Salience > 1.0:** Should rank well

---

# STAGE 6: Decision Matrix

## Goal
Determine if you're ready for mainnet deployment.

## Decision Criteria

```bash
cat > decision_matrix.sh << 'EOF'
#!/bin/bash

echo "================================================================================  "
echo "MAINNET READINESS DECISION MATRIX"
echo "================================================================================"
echo ""
echo "Review your results from Stages 1-5:"
echo ""
echo "‚ñ° Stage 1: All 11 models exist and have complete files"
echo "‚ñ° Stage 2: All 11 models load successfully"
echo "‚ñ° Stage 3: Binary avg accuracy ‚â• 65%"
echo "‚ñ° Stage 3: Overall estimated salience ‚â• 1.5"
echo "‚ñ° Stage 4: Prediction time < 5 seconds"
echo "‚ñ° Stage 5: Embeddings diverse, both classes predicted"
echo ""
echo "DECISION RULES:"
echo ""
echo "‚úÖ ALL 6 CHECKED ‚Üí EXCELLENT, DEPLOY IMMEDIATELY"
echo "   - High confidence for top 10 ranking"
echo "   - Expected salience: 1.5-2.5"
echo "   - Action: Proceed to mainnet deployment (Phase 2)"
echo ""
echo "‚úì 4-5 CHECKED ‚Üí GOOD, READY TO DEPLOY"
echo "   - Solid performance expected"
echo "   - Expected salience: 1.0-2.0"
echo "   - Action: Deploy and monitor closely"
echo ""
echo "‚ö†Ô∏è 2-3 CHECKED ‚Üí FAIR, CONSIDER IMPROVEMENTS"
echo "   - May underperform initially"
echo "   - Expected salience: 0.5-1.5"
echo "   - Action: Either (a) improve weak challenges, or (b) deploy and optimize"
echo ""
echo "‚ùå 0-1 CHECKED ‚Üí POOR, NOT READY"
echo "   - Likely to struggle on mainnet"
echo "   - Expected salience: <1.0"
echo "   - Action: Retrain before mainnet"
echo ""
echo "================================================================================"
EOF

chmod +x decision_matrix.sh
./decision_matrix.sh
```

---

# COMPLETE WORKFLOW SUMMARY

## Stage-by-Stage Expected Outcomes

### STAGE 1: Verify Training (2 minutes)
**Goal:** Confirm all models trained  
**Expected:** 11 model directories in `models/tuned/`, each with 5 files  
**Pass Criteria:** All 11 models exist  
**Next:** Stage 2

### STAGE 2: Model Loading (30 seconds)
**Goal:** Verify models load correctly  
**Expected:** All 11 models load without errors  
**Pass Criteria:** 11/11 loaded successfully  
**Next:** Stage 3

### STAGE 3: Backtest Performance (5-10 minutes)
**Goal:** Measure accuracy and salience  
**Expected:**  
  - Binary challenges: 60-70% accuracy
  - LBFGS challenges: Valid embeddings, salience 1.5-2.5
  - Overall salience: 1.0-2.0
**Pass Criteria:** Overall salience ‚â• 1.5  
**Next:** Stage 4

### STAGE 4: Speed Test (30 seconds)
**Goal:** Verify real-time capability  
**Expected:** <2 seconds per prediction  
**Pass Criteria:** <5 seconds  
**Next:** Stage 5

### STAGE 5: Diversity Test (1 minute per challenge)
**Goal:** Check embedding quality  
**Expected:**  
  - Diversity score > 1.0
  - Both classes predicted (binary)
  - No NaN/Inf values
**Pass Criteria:** Embeddings diverse, predictions varied  
**Next:** Stage 6

### STAGE 6: Decision (1 minute)
**Goal:** Determine readiness  
**Expected:** Clear go/no-go decision  
**Outcomes:**
  - ‚úÖ **DEPLOY:** ‚â•5/6 criteria passed
  - ‚ö†Ô∏è **IMPROVE FIRST:** 3-4 criteria passed
  - ‚ùå **RETRAIN:** <3 criteria passed

---

# NEXT STEPS AFTER TESTING

## Scenario A: Ready to Deploy (‚úÖ)

```bash
# Save results
cp backtest_results_*.txt production_baseline.txt
echo "READY FOR MAINNET - $(date)" > deployment_log.txt

# Proceed to mainnet
echo "Next: Follow COMPLETE_ROADMAP_TO_FIRST_PLACE.md Phase 2"
```

**Expected Mainnet Performance:**
- First week: Rank 15-25 (establishing baseline)
- Week 2-3: Rank 10-20 (after optimization)
- Week 4: Top 10 push
- Month 2: Top 5 (with continuous improvement)

---

## Scenario B: Need Improvements (‚ö†Ô∏è)

```bash
# Identify weak challenges
grep "Estimated Salience" backtest_results_*.txt | sort -k3 -n | head -3

# Retrain weakest 2-3 challenges
./run_training.sh --trials 100 --challenge WEAK_CHALLENGE_1
./run_training.sh --trials 100 --challenge WEAK_CHALLENGE_2

# Re-test
python scripts/testing/backtest_models.py
```

**Action Plan:**
1. Retrain bottom 20% of challenges
2. Re-run Stages 3-5
3. Re-assess readiness
4. Deploy when ready

---

## Scenario C: Not Ready (‚ùå)

```bash
# Full retraining needed
echo "Running comprehensive retraining..."
./run_training.sh --trials 150  # More thorough

# Or retrain all challenges separately
for challenge in ETH-LBFGS BTC-LBFGS-6H ETH-HITFIRST-100M \
                 ETH-1H-BINARY EURUSD-1H-BINARY GBPUSD-1H-BINARY \
                 CADUSD-1H-BINARY NZDUSD-1H-BINARY CHFUSD-1H-BINARY \
                 XAUUSD-1H-BINARY XAGUSD-1H-BINARY; do
    ./run_training.sh --trials 100 --challenge $challenge
done

# Re-test from Stage 1
```

**Action Plan:**
1. Check data quality
2. Review hyperparameters
3. Full retraining with more trials
4. Re-run all stages
5. Deploy only when ready

---

# EXPECTED SALIENCE SCORE RANGES

## By Challenge Type

### Binary Challenges (2D embeddings)
```
Challenge Type    | Expected Accuracy | Expected Salience
------------------+-------------------+------------------
Excellent        | 70-80%            | 0.8-1.6
Good             | 65-70%            | 0.6-1.2
Fair             | 60-65%            | 0.4-0.8
Poor             | <60%              | <0.4
```

### LBFGS Challenges (17D embeddings)
```
Challenge Type    | Embedding Std     | Expected Salience
------------------+-------------------+------------------
Excellent        | >1.0              | 2.0-3.0
Good             | 0.7-1.0           | 1.5-2.0
Fair             | 0.4-0.7           | 1.0-1.5
Poor             | <0.4              | <1.0
```

### HITFIRST Challenges (3D embeddings)
```
Challenge Type    | Embedding Std     | Expected Salience
------------------+-------------------+------------------
Excellent        | >0.8              | 1.5-2.5
Good             | 0.5-0.8           | 1.0-1.5
Fair             | 0.3-0.5           | 0.5-1.0
Poor             | <0.3              | <0.5
```

---

# QUICK REFERENCE COMMANDS

```bash
# Complete test suite (all stages)
cd /home/ocean/Nereus/SN123
source venv/bin/activate

# Stage 1-2: Verify models
ls -l models/tuned/ | wc -l  # Should be 11

# Stage 3: Backtest
python scripts/testing/backtest_models.py | tee backtest_$(date +%Y%m%d).txt

# Stage 4: Speed test
python scripts/testing/test_speed.py  # (if exists)

# Stage 5: Diversity test
python scripts/testing/test_local_salience.py --ticker ETH-1H-BINARY --model-dir models/tuned --data-dir data

# View summary
grep -A 20 "READINESS ASSESSMENT" backtest_*.txt

# Decision
./decision_matrix.sh
```

---

# TROUBLESHOOTING

## Issue: Models not found
**Symptoms:** Stage 1 shows <11 models  
**Solution:** Check training logs, retrain missing challenges
```bash
grep -i error logs/training/training_current.log
```

## Issue: Models fail to load
**Symptoms:** Stage 2 shows errors  
**Solution:** Check individual model files, retrain if corrupted
```bash
ls -la models/tuned/PROBLEM_CHALLENGE/
```

## Issue: Low accuracy (<55%)
**Symptoms:** Stage 3 shows poor performance  
**Solution:**  
1. Check data quality
2. Retrain with more trials
3. Review hyperparameters

## Issue: Slow predictions (>10s)
**Symptoms:** Stage 4 timeout  
**Solution:**
1. Reduce batch size
2. Optimize feature preparation
3. Use GPU acceleration

## Issue: Embeddings collapsed
**Symptoms:** Stage 5 shows low diversity  
**Solution:**
1. Retrain with class weights
2. Check for overfitting
3. Increase model capacity

---

# SUCCESS METRICS SUMMARY

## Minimum Thresholds for Mainnet Deployment

```
‚úÖ All 11 models exist and load
‚úÖ Binary average accuracy ‚â• 60%
‚úÖ Overall estimated salience ‚â• 1.0
‚úÖ Prediction time < 5 seconds
‚úÖ No critical errors in any stage
```

## Target Performance (First Place Potential)

```
üèÜ All 11 models optimized
üèÜ Binary average accuracy ‚â• 70%
üèÜ Overall estimated salience ‚â• 2.0
üèÜ Prediction time < 2 seconds
üèÜ High embedding diversity (>1.0)
üèÜ Both classes predicted (binary)
```

---

**Total Testing Time:** 15-30 minutes  
**Result:** Clear understanding of model quality and mainnet readiness  
**Next:** Deploy with confidence or improve specific weaknesses

**You now have a complete roadmap to test and validate your models before mainnet deployment!** üöÄ

